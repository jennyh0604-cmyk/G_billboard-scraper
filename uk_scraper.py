import os
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client

# Supabase ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

SINGLES_URL = "https://www.officialcharts.com/charts/singles-chart/"
ALBUMS_URL = "https://www.officialcharts.com/charts/albums-chart/"


def parse_stat(text: str):
    """
    'LW: 2', 'Peak: 1', 'Weeks: 6' ê°™ì€ ë¬¸ìì—´ì—ì„œ
    ìˆ«ìë§Œ ë½‘ì•„ì„œ intë¡œ ë°˜í™˜. ìˆ«ìê°€ ì—†ìœ¼ë©´ None.
    """
    nums = re.findall(r"\d+", text)
    return int(nums[0]) if nums else None




def scrape_uk_chart(url, table):
    """UK Official Charts ìŠ¤í¬ë˜í•‘ (Number n ê¸°ë°˜)"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘")
    print(f"ğŸ”— URL: {url}")
    print(f"ğŸ’¾ í…Œì´ë¸”: {table}")
    print(f"{'='*80}\n")

    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    chart_date = datetime.utcnow().strftime("%Y-%m-%d")
    results = []

    # í™”ë©´ì— ë³´ì´ëŠ” "Number 1", "Number 2" ... í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ê³¡ ì°¾ê¸°
    number_tags = soup.find_all(string=re.compile(r"^Number\s+\d+"))

    if not number_tags:
        print("[WARN] 'Number n' í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ê°€ ë°”ë€ ê²ƒ ê°™ì•„ìš”.")
        return

    for idx, num_tag in enumerate(number_tags, start=1):
        # ----- ìˆœìœ„(rank) -----
        m = re.search(r"\d+", str(num_tag))
        rank = int(m.group()) if m else None

        # ----- ì œëª© / ì•„í‹°ìŠ¤íŠ¸ -----
        # Number n ë’¤ì—ëŠ” ë³´í†µ
        # 1) Image ë§í¬ 2ê°œ
        # 2) ì œëª© ë§í¬ 1ê°œ
        # 3) ì•„í‹°ìŠ¤íŠ¸ ë§í¬ 1ê°œ
        title_link = num_tag.find_next("a")
        # Image: ... ë§í¬ëŠ” ê±´ë„ˆë›´ë‹¤
        while title_link and title_link.get_text(strip=True).startswith("Image:"):
            title_link = title_link.find_next("a")

        if not title_link:
            continue

        artist_link = title_link.find_next("a")
        if not artist_link:
            continue

        title = title_link.get_text(strip=True)
        artist = artist_link.get_text(strip=True)

        # ----- LW / Peak / Weeks -----
        lw = peak = weeks = None

        # ì•„í‹°ìŠ¤íŠ¸ ë§í¬ ì´í›„ë¡œ ë‚˜ì˜¤ëŠ” í…ìŠ¤íŠ¸ë“¤ì„ í›‘ìœ¼ë©´ì„œ
        # ë‹¤ìŒ "Number n" ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ì—ì„œ í†µê³„ë§Œ ì¶”ì¶œ
        for s in artist_link.find_all_next(string=True):
            txt = s.strip()
            if not txt:
                continue

            # ë‹¤ìŒ ê³¡ ë¸”ë¡ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ì¢…ë£Œ
            if txt.startswith("Number "):
                break

            lower = txt.lower()
            if "lw" in lower:
                lw = parse_stat(txt)
            elif "peak" in lower:
                peak = parse_stat(txt)
            elif "week" in lower:
                weeks = parse_stat(txt)

            if lw is not None and peak is not None and weeks is not None:
                break

        results.append({
            "chart_date": chart_date,
            "rank": rank,
            "title": title,
            "artist": artist,
            "last_week_rank": lw,
            "peak_rank": peak,
            "weeks_on_chart": weeks,
        })

        if idx <= 5:
            print(f"[DEBUG] #{rank} {title} / {artist} | LW={lw}, Peak={peak}, Weeks={weeks}")

    print(f"\n{'='*80}")
    print(f"âœ… ì´ {len(results)}ê°œ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"{'='*80}\n")

    if not results:
        print("âš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        return

    # Supabase ì €ì¥ (ê°™ì€ chart_date ë°ì´í„° ë¨¼ì € ì‚­ì œ í›„ ì‚½ì…)
    print(f"ğŸ’¾ {table} í…Œì´ë¸”ì— ì €ì¥ ì¤‘...")
    try:
        supabase.table(table).delete().eq("chart_date", chart_date).execute()
        print(f"   - {chart_date} ë‚ ì§œ ê¸°ì¡´ ë ˆì½”ë“œ ì‚­ì œ ì™„ë£Œ")
        supabase.table(table).insert(results).execute()
        print(f"âœ… {table} ì €ì¥ ì™„ë£Œ! (ì´ {len(results)}ê°œ)\n")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\n")
        raise



def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸµ UK Official Charts ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    print("="*80)
    
    try:
        scrape_uk_chart(SINGLES_URL, "uk_singles_entries")
        scrape_uk_chart(ALBUMS_URL, "uk_albums_entries")
        
        print("\n" + "="*80)
        print("ğŸ‰ ëª¨ë“  ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print("="*80 + "\n")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()



