import os
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client

# Supabase ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

SINGLES_URL = "https://www.officialcharts.com/charts/singles-chart/"
ALBUMS_URL = "https://www.officialcharts.com/charts/albums-chart/"


def extract_stats_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ LW, Peak, Weeks ì¶”ì¶œ"""
    lw = peak = weeks = None
    
    # LW ì¶”ì¶œ
    lw_match = re.search(r'LW:\s*(\d+)', text)
    if lw_match:
        lw = int(lw_match.group(1))
    elif re.search(r'LW:\s*(New|RE)', text, re.I):
        lw = None  # Newë‚˜ REëŠ” None ì²˜ë¦¬
    
    # Peak ì¶”ì¶œ
    peak_match = re.search(r'Peak:\s*(\d+)', text)
    if peak_match:
        peak = int(peak_match.group(1))
    
    # Weeks ì¶”ì¶œ
    weeks_match = re.search(r'Weeks:\s*(\d+)', text)
    if weeks_match:
        weeks = int(weeks_match.group(1))
    
    return lw, peak, weeks



def scrape_uk_chart(url, table):
    """UK Official Charts ìŠ¤í¬ë˜í•‘ - ì™„ì „íˆ ìƒˆë¡œìš´ ë°©ì‹"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘")
    print(f"ğŸ”— URL: {url}")
    print(f"ğŸ’¾ í…Œì´ë¸”: {table}")
    print(f"{'='*80}\n")
    
    # í˜ì´ì§€ ìš”ì²­
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    
    soup = BeautifulSoup(resp.text, "html.parser")
    chart_date = datetime.utcnow().strftime("%Y-%m-%d")
    
    # Singles / Albums êµ¬ë¶„
    is_singles = "singles" in url.lower()
    content_url_pattern = "/songs/" if is_singles else "/albums/"
    
    print(f"ğŸ“Œ ì°¨íŠ¸ ìœ í˜•: {'Singles' if is_singles else 'Albums'}")
    print(f"ğŸ“… ì°¨íŠ¸ ë‚ ì§œ: {chart_date}\n")
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    page_text = soup.get_text()
    
    # ëª¨ë“  ë§í¬ ì°¾ê¸°
    all_links = soup.find_all("a", href=True)
    
    results = []
    seen_titles = set()
    
    for link in all_links:
        href = link.get("href", "")
        text = link.get_text(strip=True)
        
        # í•´ë‹¹ ì°¨íŠ¸ì˜ ì»¨í…ì¸  ë§í¬ë§Œ ì²˜ë¦¬
        if content_url_pattern not in href:
            continue
        
        # ì´ë¯¸ì§€ ë§í¬ ì œì™¸
        if text.startswith("Image:") or not text:
            continue
        
        # ì¤‘ë³µ ì²´í¬
        if text in seen_titles:
            continue
        seen_titles.add(text)
        
        title = text
        rank = len(results) + 1
        artist = "Unknown"
        
        # ì•„í‹°ìŠ¤íŠ¸ ì°¾ê¸°: í˜„ì¬ ë§í¬ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” /artist/ ë§í¬
        next_elem = link.find_next("a", href=re.compile(r"/artist/"))
        if next_elem:
            artist_text = next_elem.get_text(strip=True)
            if artist_text and not artist_text.startswith("Image:"):
                artist = artist_text
        
        # í†µê³„ ì •ë³´ ì¶”ì¶œ: ì œëª© í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
        lw = peak = weeks = None
        title_pos = page_text.find(title)
        
        if title_pos != -1:
            # ì œëª© ìœ„ì¹˜ë¶€í„° 300ì ë²”ìœ„ì—ì„œ í†µê³„ ì°¾ê¸°
            search_text = page_text[title_pos:title_pos + 300]
            lw, peak, weeks = extract_stats_from_text(search_text)
        
        # ê²°ê³¼ ì €ì¥
        results.append({
            "chart_date": chart_date,
            "rank": rank,
            "title": title,
            "artist": artist,
            "last_week_rank": lw,
            "peak_rank": peak,
            "weeks_on_chart": weeks,
        })
        
        # ì²˜ìŒ 10ê°œ ì¶œë ¥
        if rank <= 10:
            print(f"#{rank:2d} â”‚ {title[:40]:<40} â”‚ {artist[:25]:<25}")
            lw_str = str(lw) if lw else "New"
            print(f"     LW: {lw_str:>4} â”‚ Peak: {peak or '-':>3} â”‚ Weeks: {weeks or '-'}")
            print()
    
    # í†µê³„ ì¶œë ¥
    print(f"\n{'='*80}")
    print(f"âœ… ì´ {len(results)}ê°œ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ")
    
    if results:
        lw_count = sum(1 for r in results if r["last_week_rank"] is not None)
        peak_count = sum(1 for r in results if r["peak_rank"] is not None)
        weeks_count = sum(1 for r in results if r["weeks_on_chart"] is not None)
        
        print(f"\nğŸ“Š í†µê³„ ë°ì´í„° ìˆ˜ì§‘ë¥ :")
        print(f"   â€¢ Last Week: {lw_count}/{len(results)} ({lw_count/len(results)*100:.1f}%)")
        print(f"   â€¢ Peak: {peak_count}/{len(results)} ({peak_count/len(results)*100:.1f}%)")
        print(f"   â€¢ Weeks: {weeks_count}/{len(results)} ({weeks_count/len(results)*100:.1f}%)")
    print(f"{'='*80}\n")
    
    if not results:
        print("âš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        return
    
       # Supabase ì €ì¥
    print(f"ğŸ’¾ {table} í…Œì´ë¸”ì— ì €ì¥ ì¤‘...")

    try:
        # 1) ê°™ì€ chart_date ë°ì´í„° ë¨¼ì € ì‚­ì œ
        supabase.table(table).delete().eq("chart_date", chart_date).execute()
        print(f"   - {chart_date} ë‚ ì§œ ê¸°ì¡´ ë ˆì½”ë“œ ì‚­ì œ ì™„ë£Œ")

        # 2) ìƒˆ ê²°ê³¼ ì‚½ì…
        supabase.table(table).insert(results).execute()
        print(f"âœ… {table} ì €ì¥ ì™„ë£Œ! (ì´ {len(results)}ê°œ)\n")

    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\n")
        raise



def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸµ UK Official Charts ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    print("="*80)
    
    try:
        scrape_uk_chart(SINGLES_URL, "uk_singles_entries")
        scrape_uk_chart(ALBUMS_URL, "uk_albums_entries")
        
        print("\n" + "="*80)
        print("ğŸ‰ ëª¨ë“  ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print("="*80 + "\n")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()


