import os
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client

# ---------------------------------------------------
# Supabase ì„¤ì •
# ---------------------------------------------------
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

SINGLES_URL = "https://www.officialcharts.com/charts/singles-chart/"
ALBUMS_URL = "https://www.officialcharts.com/charts/albums-chart/"


# ---------------------------------------------------
# ê³µí†µ ìœ í‹¸
# ---------------------------------------------------
def parse_stat(text: str):
    """
    'LW: 2' / 'Last week: 2' / 'Weeks: 6' ê°™ì€ ë¬¸ìì—´ì—ì„œ
    ìˆ«ìë§Œ ë½‘ì•„ì„œ intë¡œ ë°˜í™˜. ìˆ«ìê°€ ì—†ìœ¼ë©´ None.
    """
    nums = re.findall(r"\d+", text)
    return int(nums[0]) if nums else None


# ---------------------------------------------------
# ë©”ì¸ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# ---------------------------------------------------
def scrape_uk_chart(url: str, table: str):
    print(f"\n=== UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘ ===")
    print(f"[URL] {url}")
    print(f"[TABLE] {table}\n")

    resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    # ì¼ë‹¨ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì°¨íŠ¸ ë‚ ì§œë¡œ ì‚¬ìš©
    chart_date = datetime.utcnow().strftime("%Y-%m-%d")
    results = []

    # í™”ë©´ì— ë³´ì´ëŠ” "Number 1", "Number 2" ... í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ê³¡ ì°¾ê¸°
    number_tags = soup.find_all(string=re.compile(r"Number\s+\d+"))

    if not number_tags:
        print("[WARN] 'Number n' í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ê°€ ë°”ë€ ê²ƒ ê°™ì•„ìš”.")
        return

    for idx, num_tag in enumerate(number_tags, start=1):
        # ----- ìˆœìœ„(rank) -----
        m = re.search(r"\d+", str(num_tag))
        rank = int(m.group()) if m else None

        # ----- ì œëª© / ì•„í‹°ìŠ¤íŠ¸ -----
        # 'Number n' ì´í›„ì— ë‚˜ì˜¤ëŠ” a íƒœê·¸ë“¤ ì¤‘
        # í…ìŠ¤íŠ¸ê°€ 'Image:' ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì€ ì»¤ë²„ ì´ë¯¸ì§€ë¼ì„œ ì œì™¸
        title = "Unknown"
        artist = "Unknown"

        candidate_links = num_tag.find_all_next("a", limit=8)
        non_image_links = []
        for a in candidate_links:
            txt = a.get_text(strip=True)
            if not txt:
                continue
            if txt.startswith("Image:"):
                continue
            non_image_links.append(a)

        if len(non_image_links) >= 1:
            title = non_image_links[0].get_text(strip=True)
        if len(non_image_links) >= 2:
            artist = non_image_links[1].get_text(strip=True)

        # ----- LW / Peak / Weeks -----
        lw = peak = weeks = None

        # í†µê³„ í…ìŠ¤íŠ¸ëŠ” ë³´í†µ ì œëª©/ì•„í‹°ìŠ¤íŠ¸ ë°”ë¡œ ë’¤ì— ë‚˜ì˜¤ëŠ” ë¦¬ìŠ¤íŠ¸ì— ìˆìŒ
        # ë§ˆì§€ë§‰ non_image ë§í¬ ë’¤ì—ì„œë¶€í„° ë¬¸ìì—´ë“¤ì„ í›‘ìœ¼ë©´ì„œ ì°¾ëŠ”ë‹¤.
        start_anchor = non_image_links[-1] if non_image_links else num_tag

        for s in start_anchor.find_all_next(string=True):
            txt = s.strip()
            if not txt:
                continue

            # ë‹¤ìŒ ê³¡ì˜ "Number n"ì„ ë§Œë‚˜ë©´ í˜„ì¬ ê³¡ ë¸”ë¡ ì¢…ë£Œ
            if re.search(r"Number\s+\d+", txt):
                break

            lower = txt.lower()
            if "lw" in lower or "last" in lower:
                lw = parse_stat(txt)
            elif "peak" in lower:
                peak = parse_stat(txt)
            elif "week" in lower:
                weeks = parse_stat(txt)

            if lw is not None and peak is not None and weeks is not None:
                break

        results.append({
            "chart_date": chart_date,
            "rank": rank,
            "title": title,
            "artist": artist,
            "last_week_rank": lw,
            "peak_rank": peak,
            "weeks_on_chart": weeks,
        })

        # ì²˜ìŒ ëª‡ ê°œëŠ” ë¡œê·¸ë¡œ í™•ì¸
        if idx <= 3:
            print(f"[DEBUG] rank={rank}, title={title}, artist={artist}, "
                  f"LW={lw}, Peak={peak}, Weeks={weeks}")

    # ---------------------------------------------------
    # Supabase ì—…ì„œíŠ¸
    # ---------------------------------------------------
    print(f"\n{table} â†’ {len(results)}ê°œ í•­ëª© ì—…ì„œíŠ¸ ì¤‘â€¦")
    supabase.table(table).upsert(results).execute()
    print(f"{table} ì €ì¥ ì™„ë£Œ! âœ…\n")


# ---------------------------------------------------
# main
# ---------------------------------------------------
def main():
    scrape_uk_chart(SINGLES_URL, "uk_singles_entries")
    scrape_uk_chart(ALBUMS_URL, "uk_albums_entries")
    print("ğŸ‰ ëª¨ë“  UK ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
