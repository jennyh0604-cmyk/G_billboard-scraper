import os
import re
from datetime import datetime
from typing import List, Dict, Optional

import requests
from bs4 import BeautifulSoup


# ===== 0. Supabase ì„¤ì • =====

SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

BASE_REST_URL = SUPABASE_URL.rstrip("/") + "/rest/v1"

BASE_HEADERS = {
    "apikey": SUPABASE_SERVICE_KEY,
    "Authorization": f"Bearer {SUPABASE_SERVICE_KEY}",
    "Content-Type": "application/json",
}


# ===== 1. ê³µí†µ ìœ í‹¸ =====

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0 Safari/537.36"
    )
}


def safe_int(value: Optional[str]) -> Optional[int]:
    """ìˆ«ìì²˜ëŸ¼ ë³´ì´ë©´ int, ì•„ë‹ˆë©´ None."""
    if not value:
        return None
    value = value.strip()
    if not value.isdigit():
        return None
    return int(value)


def extract_chart_date(text: str) -> Optional[str]:
    """
    ì˜ˆì‹œ: '14 November 2025 - 20 November 2025'
    ì•ìª½ ë‚ ì§œ(14 November 2025)ë¥¼ chart_date ë¡œ ì‚¬ìš©.
    """
    m = re.search(r"(\d{1,2} \w+ \d{4})\s*-\s*(\d{1,2} \w+ \d{4})", text)
    if not m:
        return None

    start_str = m.group(1)
    try:
        d = datetime.strptime(start_str, "%d %B %Y").date()
        return d.isoformat()
    except ValueError:
        return None


def parse_officialcharts_text(raw_text: str) -> List[Dict]:
    """
    Official Charts í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸(raw_text)ë¥¼ ë°›ì•„ì„œ
    rank / title / artist / LW / Peak / Weeks / chart_date ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    """
    chart_date = extract_chart_date(raw_text)

    # ğŸ‘‰ ë…¸ë¸Œë ˆì´í¬ ìŠ¤í˜ì´ìŠ¤(\xa0)ë¥¼ ì¼ë°˜ ê³µë°±ìœ¼ë¡œ í†µì¼
    text = raw_text.replace("\xa0", " ")

    # "Number <ìˆœìœ„>" íŒ¨í„´ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œê¸°
    parts = re.split(r"Number\s+(\d+)", text)
    entries: List[Dict] = []

    # parts êµ¬ì¡°: ["ì•ë¶€ë¶„", "1", "<1ë²ˆ ë‚´ìš©>", "2", "<2ë²ˆ ë‚´ìš©>", ...]
    if len(parts) < 3:
        print("[DEBUG] 'Number <n>' íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return []

    for i in range(1, len(parts), 2):
        rank_str = parts[i]
        body = parts[i + 1]

        rank = safe_int(rank_str)
        if rank is None:
            continue

        # ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê³ , ê³µë°± ì œê±°
        lines = [ln.strip() for ln in body.splitlines()]
        lines = [ln for ln in lines if ln]  # ë¹ˆ ì¤„ ì œê±°

        # "Image: ... cover art" ê°™ì€ ì¡ìŒ ë¼ì¸ì€ ì œê±°
        while lines and (
            lines[0].startswith("Image:")
            or "cover art" in lines[0]
            or lines[0].startswith("view as")
            or lines[0].startswith("Official Singles Chart")
            or lines[0].startswith("Official Albums Chart")
        ):
            lines.pop(0)

        if len(lines) < 2:
            # ì œëª© + ì•„í‹°ìŠ¤íŠ¸ ë‘ ì¤„ì´ ì•ˆ ë‚˜ì˜¤ë©´ ìŠ¤í‚µ
            continue

        title = lines[0]
        artist = lines[1]

        # LW / Peak / Weeks ê°’ì€ body ì „ì²´ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ì°¾ê¸°
        m_lw = re.search(r"LW:\s*([0-9]+|New|RE)", body, re.IGNORECASE)
        m_peak = re.search(r"Peak:\s*([0-9]+)", body, re.IGNORECASE)
        m_weeks = re.search(r"Weeks:\s*([0-9]+)", body, re.IGNORECASE)

        if m_lw:
            lw_raw = m_lw.group(1)
            # "New", "RE" ê°™ì€ ê±´ None ì²˜ë¦¬
            last_week_rank = safe_int(lw_raw)
        else:
            last_week_rank = None

        peak_rank = safe_int(m_peak.group(1)) if m_peak else None
        weeks_on_chart = safe_int(m_weeks.group(1)) if m_weeks else None

        entries.append(
            {
                "rank": rank,
                "title": title,
                "artist": artist,
                "last_week_rank": last_week_rank,
                "peak_rank": peak_rank,
                "weeks_on_chart": weeks_on_chart,
                "chart_date": chart_date,
            }
        )

    return entries



def fetch_official_chart(chart_path: str) -> List[Dict]:
    """
    chart_path ì˜ˆì‹œ:
      - 'singles-chart/'
      - 'albums-chart/'
    """
    url = f"https://www.officialcharts.com/charts/{chart_path}"
    print(f"[UK] ìš”ì²­ URL: {url}")

    resp = requests.get(url, headers=HEADERS, timeout=20)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "html.parser")
    raw_text = soup.get_text("\n", strip=True)

    entries = parse_officialcharts_text(raw_text)
    print(f"[UK] {chart_path} ì—ì„œ {len(entries)}ê°œ í•­ëª© íŒŒì‹±")
    return entries


# ===== 2. Supabase REST ë¡œ ì €ì¥ =====

def replace_entries_for_date(table_name: str, entries: List[Dict]) -> None:
    """ê°™ì€ chart_date ë°ì´í„° ì‹¹ ì§€ìš°ê³  ìƒˆë¡œ ë„£ê¸°."""
    if not entries:
        print(f"[WARN] {table_name}: ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    chart_date = entries[0]["chart_date"]
    if not chart_date:
        print(f"[WARN] {table_name}: chart_date ì—†ìŒ, ì €ì¥ ìŠ¤í‚µ.")
        return

    # 1) í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì‚­ì œ
    delete_url = f"{BASE_REST_URL}/{table_name}?chart_date=eq.{chart_date}"
    print(f"[Supabase] {table_name} {chart_date} ë°ì´í„° ì‚­ì œ: {delete_url}")
    r_del = requests.delete(delete_url, headers=BASE_HEADERS, timeout=20)
    if not r_del.ok:
        print(f"[Supabase] {table_name} ì‚­ì œ ì‹¤íŒ¨: {r_del.status_code} {r_del.text}")

    # 2) ìƒˆ ë°ì´í„° insert
    insert_url = f"{BASE_REST_URL}/{table_name}"
    headers = {**BASE_HEADERS, "Prefer": "return=representation"}
    print(f"[Supabase] {table_name} {len(entries)}ê°œ í–‰ insert...")
    r_ins = requests.post(insert_url, headers=headers, json=entries, timeout=30)
    if not r_ins.ok:
        print(f"[ERROR] {table_name} insert ì‹¤íŒ¨: {r_ins.status_code} {r_ins.text}")
        r_ins.raise_for_status()
    else:
        print(f"[OK] {table_name} insert ì™„ë£Œ.")


# ===== 3. ì‹¤ì œ ìŠ¤í¬ë˜í•‘ & ì €ì¥ íë¦„ =====

def update_uk_singles_chart():
    print("=== UK Official Singles Chart ìŠ¤í¬ë˜í•‘ ì‹œì‘ ===")
    entries = fetch_official_chart("singles-chart/")
    replace_entries_for_date("uk_singles_entries", entries)
    print("=== UK Official Singles Chart ìŠ¤í¬ë˜í•‘ ì¢…ë£Œ ===\n")


def update_uk_albums_chart():
    print("=== UK Official Albums Chart ìŠ¤í¬ë˜í•‘ ì‹œì‘ ===")
    entries = fetch_official_chart("albums-chart/")
    replace_entries_for_date("uk_albums_entries", entries)
    print("=== UK Official Albums Chart ìŠ¤í¬ë˜í•‘ ì¢…ë£Œ ===\n")


if __name__ == "__main__":
    try:
        update_uk_singles_chart()
        update_uk_albums_chart()
        print("ëª¨ë“  UK ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ âœ…")
    except Exception:
        import traceback

        print("[FATAL] UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        traceback.print_exc()
        raise


