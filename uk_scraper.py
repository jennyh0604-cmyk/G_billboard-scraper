import os
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client


SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

SINGLES_URL = "https://www.officialcharts.com/charts/singles-chart/"
ALBUMS_URL = "https://www.officialcharts.com/charts/albums-chart/"


def parse_stat(text: str):
    """ 'LW: 2', 'Peak: 1', 'Weeks: 6' â†’ ìˆ«ìë§Œ ë°˜í™˜ """
    nums = re.findall(r"\d+", text)
    return int(nums[0]) if nums else None


def scrape_uk_chart(url: str, table: str):
    print(f"\n=== UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘ ===\n[URL] {url}\n")

    resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    # ì°¨íŠ¸ ë‚ ì§œ
    chart_date = datetime.utcnow().strftime("%Y-%m-%d")

    results = []

    # "Number 1", "Number 2" ... íŒ¨í„´ìœ¼ë¡œ ì „ì²´ ê³¡ ì°¾ê¸°
    number_tags = soup.find_all(string=re.compile(r"^Number\s+\d+"))

    if not number_tags:
        print("[ê²½ê³ ] 'Number n' íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„± ìˆìŒ.")
        return

    for num_tag in number_tags:
        # rank íŒŒì‹±
        m = re.search(r"\d+", num_tag)
        rank = int(m.group()) if m else None

        # ë‹¤ìŒ ë‘ <a> íƒœê·¸: ì²« ë²ˆì§¸ëŠ” ì œëª©, ë‘ ë²ˆì§¸ëŠ” ì•„í‹°ìŠ¤íŠ¸
        title_tag = num_tag.find_next("a")
        if not title_tag:
            continue
        artist_tag = title_tag.find_next("a")
        if not artist_tag:
            continue

        title = title_tag.get_text(strip=True)
        artist = artist_tag.get_text(strip=True)

        # LW / Peak / Weeks ì°¾ê¸°
        lw = peak = weeks = None

        # ì•„í‹°ìŠ¤íŠ¸ íƒœê·¸ ë’¤ì—ì„œ ë‹¤ìŒ Number ë°œìƒ ì „ê¹Œì§€ íƒìƒ‰
        for s in artist_tag.find_all_next(string=True):
            txt = s.strip()
            if not txt:
                continue

            # ë‹¤ìŒ ê³¡ì„ ë§Œë‚˜ë©´ break
            if txt.startswith("Number "):
                break

            if txt.startswith("LW"):
                lw = parse_stat(txt)
            elif txt.startswith("Peak"):
                peak = parse_stat(txt)
            elif txt.startswith("Weeks"):
                weeks = parse_stat(txt)

            if lw is not None and peak is not None and weeks is not None:
                break

        results.append({
            "chart_date": chart_date,
            "rank": rank,
            "title": title,
            "artist": artist,
            "last_week_rank": lw,
            "peak_rank": peak,
            "weeks_on_chart": weeks,
        })

    print(f"{table} â†’ {len(results)}ê°œ í•­ëª© ì €ì¥ ì¤‘â€¦")
    supabase.table(table).upsert(results).execute()
    print(f"{table} ì €ì¥ ì™„ë£Œ! ğŸ‰\n")


def main():
    scrape_uk_chart(SINGLES_URL, "uk_singles_entries")
    scrape_uk_chart(ALBUMS_URL, "uk_albums_entries")
    print("ğŸ‡¬ğŸ‡§ UK ì°¨íŠ¸ ì „ì²´ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
