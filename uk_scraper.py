import os
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client

# ---------------------------------------------------
# Supabase ì„¤ì •
# ---------------------------------------------------
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_SERVICE_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ SUPABASE_URL / SUPABASE_SERVICE_KEY ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

supabase = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)

SINGLES_URL = "https://www.officialcharts.com/charts/singles-chart/"
ALBUMS_URL = "https://www.officialcharts.com/charts/albums-chart/"


def scrape_uk_chart(url: str, table: str):
    """UK Official Charts ìŠ¤í¬ë˜í•‘"""
    print(f"\n{'='*60}")
    print(f"UK ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    print(f"URL: {url}")
    print(f"TABLE: {table}")
    print(f"{'='*60}\n")

    # í˜ì´ì§€ ìš”ì²­
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    # ì°¨íŠ¸ ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    chart_date = datetime.utcnow().strftime("%Y-%m-%d")

    results = []
    current_rank = 0

    # ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡°: ê° ê³¡ì´ ë§í¬ë¡œ ë˜ì–´ ìˆê³ , ê·¸ ë’¤ì— í†µê³„ ì •ë³´ê°€ ë‚˜ì˜´
    # íŒ¨í„´: [ê³¡ ë§í¬] [ê°€ìˆ˜ ë§í¬] - LW: X, Peak: Y, Weeks: Z
    
    # ëª¨ë“  ë§í¬ ì°¾ê¸°
    all_links = soup.find_all("a", href=True)
    
    i = 0
    while i < len(all_links):
        link = all_links[i]
        href = link.get("href", "")
        text = link.get_text(strip=True)
        
        # ì»¤ë²„ ì´ë¯¸ì§€ ìŠ¤í‚µ
        if text.startswith("Image:") or not text:
            i += 1
            continue
        
        # ê³¡ ë§í¬ ì°¾ê¸° (/songs/ í¬í•¨)
        if "/songs/" in href:
            current_rank += 1
            
            title = text
            artist = "Unknown"
            lw = peak = weeks = None
            
            # ë‹¤ìŒ ë§í¬ê°€ ì•„í‹°ìŠ¤íŠ¸ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
            if i + 1 < len(all_links):
                next_link = all_links[i + 1]
                next_href = next_link.get("href", "")
                next_text = next_link.get_text(strip=True)
                
                # ì•„í‹°ìŠ¤íŠ¸ ë§í¬ í™•ì¸
                if "/artist/" in next_href and next_text:
                    artist = next_text
                    i += 1  # ì•„í‹°ìŠ¤íŠ¸ ë§í¬ ê±´ë„ˆë›°ê¸°
            
            # í˜„ì¬ ë§í¬ ì£¼ë³€ í…ìŠ¤íŠ¸ì—ì„œ í†µê³„ ì •ë³´ ì¶”ì¶œ
            # ë¶€ëª¨ ë˜ëŠ” í˜•ì œ ìš”ì†Œì—ì„œ "LW:", "Peak:", "Weeks:" ì°¾ê¸°
            parent = link.find_parent(["div", "section", "li", "p"])
            if parent:
                stats_text = parent.get_text()
            else:
                # ë‹¤ìŒ ëª‡ ê°œì˜ ìš”ì†Œì—ì„œ ì°¾ê¸°
                stats_text = ""
                for j in range(i, min(i + 10, len(all_links))):
                    if "/songs/" in all_links[j].get("href", ""):
                        break  # ë‹¤ìŒ ê³¡ ì‹œì‘
                    stats_text += " " + all_links[j].get_text()
            
            # ì •ê·œì‹ìœ¼ë¡œ í†µê³„ ì¶”ì¶œ
            lw_match = re.search(r"LW[:\s]*(\d+|New|RE)", stats_text, re.I)
            if lw_match:
                lw_val = lw_match.group(1)
                if lw_val.isdigit():
                    lw = int(lw_val)
                # "New"ë‚˜ "RE"ëŠ” Noneìœ¼ë¡œ ì²˜ë¦¬
            
            peak_match = re.search(r"Peak[:\s]*(\d+)", stats_text, re.I)
            if peak_match:
                peak = int(peak_match.group(1))
            
            weeks_match = re.search(r"Weeks[:\s]*(\d+)", stats_text, re.I)
            if weeks_match:
                weeks = int(weeks_match.group(1))
            
            # ê²°ê³¼ ì €ì¥
            results.append({
                "chart_date": chart_date,
                "rank": current_rank,
                "title": title,
                "artist": artist,
                "last_week_rank": lw,
                "peak_rank": peak,
                "weeks_on_chart": weeks,
            })
            
            # ë””ë²„ê·¸: ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            if current_rank <= 5:
                print(f"#{current_rank:2d} | {title[:40]:<40} | {artist[:30]:<30}")
                print(f"      LW: {lw or 'N/A':<4} | Peak: {peak or 'N/A':<4} | Weeks: {weeks or 'N/A'}")
                print()
        
        i += 1
    
    # ê²°ê³¼ í™•ì¸
    print(f"\nì´ {len(results)}ê°œ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ")
    
    if not results:
        print("[ê²½ê³ ] ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. HTML êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    
    # Supabase ì—…ì„œíŠ¸
    print(f"\n{table} í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥ ì¤‘...")
    try:
        supabase.table(table).upsert(results).execute()
        print(f"âœ… {table} ì €ì¥ ì™„ë£Œ!\n")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì²« ë²ˆì§¸ í•­ëª© ì¶œë ¥
        if results:
            print(f"ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ: {results[0]}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        scrape_uk_chart(SINGLES_URL, "uk_singles_entries")
        scrape_uk_chart(ALBUMS_URL, "uk_albums_entries")
        print(f"\n{'='*60}")
        print("ğŸ‰ ëª¨ë“  UK ì°¨íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print(f"{'='*60}\n")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()
